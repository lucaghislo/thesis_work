export SPARK_HOME=/usr/local/spark	
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
source ~/.bashrc
start-master.sh
start-slave.sh --cores 4 --memory 4g spark://luca-thinkpad:7077
export HADOOP_HOME=/home/luca/hadoop-2.9.2-src

ssh localhost

start-dfs.sh
start-yarn.sh

http://localhost:8088	
http://localhost:9870
http://localhost:8080
http://localhost:4040

hdfs dfs -ls /
hdfs dfs -rm -R /folder
hdfs dfs -put /local_file_path /hdfs_file_path
hdfs dfs -copyToLocal /hdfs_file_path /local_file_path
hdfs dfs -rm -R /input/spark

stop-dfs.sh
stop-yarn.sh

$SPARK_HOME/bin/spark-shell

      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.4.5
      /_/

scala> :load /home/luca/Documents/ANONYMIZER5_PAPER/SSG_UDF.scala
scala> val data = spark.read.format("csv").option("header", "true").load("/home/luca/Documents/ANONYMIZER4_UDF/data/health_dataset/healthdata.csv")
